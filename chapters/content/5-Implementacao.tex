\chapter{Implementação}
\label{sec:5-Implementacao}

Este capítulo aprofunda o processo de desenvolvimento da solução para o problema do projeto e os 
princípios de \textit{design} discutidos no capítulo anterior. Além disso, é efetuada uma análise 
cuidada dos resultados obtidos através das decisões anteriores, revelando os resultados
consequentes e a sua concordância com os objetivos discutidos anteriormente.

\section{Tecnologias Utilizadas}

Durante o desenvolvimento do projeto, foram utilizadas várias tecnologias e ferramentas para a 
implementação da solução. Entre as mais relevantes, destacam-se:

\begin{itemize}
  \item \textbf{Apache Storm \cite{storm}:} \textit{Framework} de processamento de 
    \textit{streaming} em tempo real (cf. \ref{sec:storm});
  \item \textbf{Apache Kafka \cite{kafka}:} Plataforma de mensagens distribuída (cf. \ref{sec:kafka});
  \item \textbf{Apache Zookeeper \cite{zookeeper}:} Serviço de coordenação distribuída - (cf.
    \ref{sec:zookeeper});
  \item \textbf{Grafana \cite{grafana}:} Plataforma de análise e visualização de dados (cf. 
    \ref{sec:metrics});
  \item \textbf{Jenkins \cite{jenkins}:} Servidor de automação de \textit{builds} - (cf.
    \ref{sec:ci-cd});
  \item \textbf{Nimbus \cite{nimbus}:} Servidor centralizado que coordena e distribui as topologias 
    do \textit{Apache Storm} (cf. \ref{sec:storm});
  \item \textbf{Splunk \cite{splunk}:} Plataforma de análise de eventos e dados (cf. \ref{sec:logs}).
\end{itemize}

\section{Descrição da implementação}

De forma a conseguir atingir os objetivos pretendidos, é necessário ter em conta vários processos
que fazem parte da implementação da solução. Para facilitar a compressão e análise dos mesmos vão 
ser apresentados os vários passos e algum suporte, como diagramas, que ajudam a ter uma melhor 
compreensão de todo o processo necessário para atingir estes objetivos.

\subsection{Processo de \ac{CI} de um serviço}

Todos os serviços hospedados na infraestrutura da Blip seguem a abordagem de \ac{IaC} pelo que 
todos os processos manuais de alocação de recursos, configurações de \textit{subnets}, entre 
outras configurações relevantes para a implantação de um serviço, são geridas automaticamente
através da \textit{framework} interna gerida por equipas de infraestrutura.

Cada serviço é composto, normalmente, por três componentes principais, como ilustrado na Figura
\ref{package}, separados em diferentes repositórios. Os três componentes habituais de um novo 
serviço são: 

\begin{itemize}
  \item \textbf{Código do serviço}: Código com toda a lógica de programação que compõe o serviço;
  \item \textbf{Configurações do pacote}: Configurações do serviço, como versões de serviços 
  externos necessários nas \ac{VM} que são necessárias para o serviço, esta componente usa 
ferramentas de configuração como Chef \cite{chef} ou Ansible \cite{ansible} 
  \item \textbf{Configurações de infraestrutura}: Configurações de infraestrutura necessárias para 
    o serviço, como especificações dos \glspl{flavour} e das \textit{subnets} necessárias.
\end{itemize}

Esta separação permite que, ao criar um novo pacote, seja possível utilizar configurações de
versões anteriores. Este pormenor torna-se bastante útil quando estão a ser efetuadas várias
alterações a nível do código do serviço e das suas configurações e é necessária a integração 
faseada destas alterações nos diferentes ambientes, por exemplo.

\begin{figure}[H]
  \centerline{\includegraphics[scale=0.5]{media/content/impl/service-composition.png}}
  \caption{Composição típica do pacote de um serviço}
  \label{package}
\end{figure}

Todo o processo de \ac{CI} é gerido pelo Jenkins e pelo \textit{Go Pipelines}, que são responsáveis
por criar os artefactos necessários para a execução do serviço nos ambientes que estão ativos. 
A Figura \ref{ci-process} ilustra, de forma simplificada, o processo de \ac{CI} de um serviço.

\begin{figure}[H]
  \centerline{\includegraphics[scale=0.2]{media/content/impl/ci-process.png}}
  \caption{Processo de \ac{CI} de um serviço}
  \label{ci-process}
\end{figure}

Após este processo de criação de um artefacto (pacote) o Jenkins envia este novo pacote para as
\glspl{pipeline}, controladas pelo \textit{Go Pipelines} de forma a começar o processo de 
implantação da nova versão. Já nas \glspl{pipeline} a responsabilidade de gestão do pacote passa a 
ser do Go, que permite automatizar vários processos a nível da infraestrutura para automatizar o 
processo de implantação deste serviço na \textit{cloud}. Como temos vários ambientes presentes para 
cada serviço, por exemplo, \ac{QA}, desenvolvimento e produção é possível configurar o plano de 
promoções de um pacote por estes ambientes. Um pacote começa por ficar apenas disponível no 
ambiente de QA e, tipicamente, a \gls{pipeline} é executada automaticamente pelo próprio 
\textit{Job Jenkins} que criou o pacote. De seguida, após uma implantação bem sucedida no ambiente 
de QA, por exemplo, o pacote é promovido para o ambiente de desenvolvimento, logo, passa a ser 
o pacote disponibilizado caso pretendamos correr a \gls{pipeline} desse ambiente. Este comportamento 
é totalmente personalizavel e adapta-se aos ambientes que cada serviço tem disponíveis. Este tipo 
de mecanismo de promoções de pacotes ajuda a prevenir que um pacote defeituoso seja implantado em 
ambientes produtivos, onde impactam clientes, sem existir a garantia que estão a funcionar 
corretamente nos ambientes de desenvolvimento.

Este processo é válido para os serviços - \ac{TLA} - que, neste caso, são os nossos \glspl{cluster}.
Já no caso das topologias o processo é ligeiramente diferente. A composição, em termos de 
repositórios é em todo semelhante à descrita anteriormente, à exceção do repositório de configurações,
mas o processo de \ac{CI} é ligeiramente diferente. Neste caso, o processo já não recorre ao 
\textit{Go pipelines} e é totalmente automatizado usando Jenkins. Existem três \textit{Jenkins Jobs} 
para a criação dos artefactos - \textit{<topologia>\_ci\_config}, \textit{<topologia>\_ci\_service}
e \textit{<topologia>\_<env>\_release}, por exemplo: \textit{xpto\_prd\_release}. Mais uma vez o 
processo é semelhante: os primeiros dois \textit{jobs} são responsáveis por criar os artefactos 
que compõe o pacote final e o último é responsável por fazer a sua implantação para o ambiente 
especificado.

\subsection{\textit{Scaledown} do Cluster}

Um dos processos necessários para conseguir atingir a solução pretendida é efetuar a alteração
de configurações do uso de recursos (\gls{flavour}) dos \glspl{cluster} existentes. Como
referido anteriormente, todos os processos de infraestrutura são geridos internamente pela Blip e,
desta forma, têm os seus processos próprios para este tipo de operações.

Neste caso, as configurações dos recursos dos serviços é efetuado a partir de um repositório 
de configurações específicas de infraestrutura para cada um dos serviços. Ao efetuar uma alteração
neste repositório é automaticamente executado um Job Jenkins que trata da criação do artefacto
da nova versão e executa a \gls{pipeline} correspondente no ambiente de \ac{QA}.

Todo este processo é automatizado e, por isso, é necessário compreender quais são os mecanismos
existentes de forma a trabalhar de forma eficiente com os mesmos. A Figura \ref{scaledown-nxt} 
ilustra o processo de \textit{scaledown} de um \textit{cluster} no ambiente de NXT e qual o 
procedimento adicional em caso de necessidade de reversão da operação, na forma de \ac{BPMN}.

\begin{figure}[H]
  \centerline{\includegraphics[scale=0.1]{media/content/impl/scaledown_nxt.png}}
  \caption{Processo de \textit{scaledown} de um \textit{cluster} no ambiente de NXT}
  \label{scaledown-nxt}
\end{figure}

\subsection{Criação de um Cluster}

Para conseguir implementar a solução descrita anteriormente um dos passos necessários é a criação
de um novo \gls{cluster}. Este processo segue a lógica de criação de um novo serviço, ou \ac{TLA}, 
e tem vários passos pouco relevantes de um ponto de vista técnico já que servem para processos de 
controlo de qualidade interna. De uma forma simplificada, o processo segue os passos apresentados 
na Figura \ref{create-tla}, na forma de \ac{BPMN}.

\begin{figure}[H]
  \centerline{\includegraphics[scale=0.12]{media/content/impl/create-tla.png}}
  \caption{Processo de criação de um novo TLA}
  \label{create-tla}
\end{figure}

Após ter aprovação neste processo, o novo \gls{cluster} está pronto a ser utilizado. Há mais 
alguns passos necessários em alguns casos, como é o caso deste \gls{cluster} em que ainda é
necessário proceder à configuração do \textit{Load Balancer}. Além disso, é necessário 
configurar as \ac{ACL} para permitir que as topologias consigam comunicar com os restantes
componentes.

\section{Testes}

De forma a testar a solução desenvolvida, foram efetuados vários testes, tanto por parte das
equipas de desenvolvimento, responsáveis por cada um dos serviços presentes no \gls{cluster},
como por parte da nossa equipa de operações. 

De um ponto de vista operacional, os testes efetuados foram focados na utilização geral de
recursos do \gls{cluster}. Para isso, foram efetuadas comparações entre os recursos registados
nos \textit{dashboards} de Grafana antes e depois da implementação da solução, utilizando testes 
de carga para simular situações de utilização de recursos exigentes de carga superior ao de dias
de pico de utilização dos serviços. Este tipo de testes já são efetuados regularmente, mas foram
reforçados durante o período de implementação da solução para garantir que a implementação não
afetava o desempenho do sistema. A implementação era considerada bem sucedida se a utilização de
recursos do \gls{cluster} não aumentasse de forma significativa após a implementação da solução
durante uma semana de utilização e testes.

Como a redução inicial teve por base apenas a redução do \gls{flavour} do \ac{CPU}, vamos ter em
conta apenas essa métrica. Como é possível observar na Figura \ref{usage-before}, a utilização de 
\ac{CPU} do \gls{cluster} antes da implementação ronda os 20\% de uso total.

\begin{figure}[H]
  \centerline{\includegraphics[scale=0.25]{media/content/impl/grafana-before.png}}
  \caption{Utilização de recursos do \textit{cluster} antes da implementação da solução}
  \label{usage-before}
\end{figure}

Após a redução de recursos inicial é possível verificar, na Figura \ref{usage-after}, que o uso 
de CPU aumentou para os 35\%, um aumento no nível esperado dada a alteração que foi efetuada. É 
importante, perceber que o \gls{cluster} mantém a sua capacidade de processar dados em momentos de 
carga elevada de forma a poder concluir que esta alteração não vai impactar negativamente o 
desempenho percetível do sistema. 

\begin{figure}[H]
  \centerline{\includegraphics[scale=0.5]{media/content/impl/grafana-after.png}}
  \caption{Utilização de recursos do \textit{cluster} após a implementação da solução}
  \label{usage-after}
\end{figure}

Além disso, foram efetuados testes manuais através de injeção de mensagens nos \textit{providers}
através de ferramentas internas de forma a garantir que a migração das topologias para o novo
\gls{cluster} foi efetuada com sucesso e todas as topologias continuavam a ser capazes de comunicar
com o restante fluxo existente.

\section{Avaliação da Solução}

Após a implementação de todas as alterações necessárias para atingir os objetivos propostos, é
possível concluir que a solução desenvolvida foi bem sucedida. A redução de recursos efetuada
permitiu uma redução de uso dos recursos significativa, sem impacto negativo no desempenho do sistema.

A abordagem iterativa e incremental permitiu uma implementação mais eficiente e com menos riscos
associados. Para além disso, a utilização de ferramentas automáticas para os processos de \ac{CI} e
\ac{CD} permitiu uma implementação mais rápida e eficiente, reduzindo o tempo necessário para a 
implementação da solução.

A conceção de várias alternativas para a solução permitiu uma análise mais cuidada dos prós e contras
de cada uma, o que permitiu uma escolha mais informada e permitiu analisar as várias consequências
de cada uma das alternativas.

A solução foi apenas implementada e testada em todos os ambientes exceto o de produção - \ac{QA},
desenvolvimento e performance - mas os resultados obtidos nestes ambientes permitem concluir que a
implementação da solução no ambiente de produção não terá impacto negativo no desempenho do sistema.

